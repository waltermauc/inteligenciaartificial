{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IMPORTAR neomdel\n",
    "from neomodel import StructuredNode, StringProperty, RelationshipTo, RelationshipFrom, config, IntegerProperty, UniqueIdProperty, UniqueIdProperty\n",
    "\n",
    "#URL CONECCION CON LA BASE DE DARTOS DE NEO4J\n",
    "config.DATABASE_URL = 'bolt://neo4j:cuenca@localhost:11005'\n",
    "\n",
    "#CREAR Object Browsers\n",
    "class Browsers(StructuredNode):\n",
    "    nombre = StringProperty(unique_index=True)\n",
    "    alcalde = RelationshipTo('AlcaldeNoticias','BROWSERS ALCALDE')\n",
    "    alcaldeFacebook = RelationshipTo('AlcaldeFacebook','BROWSERS ALCALDE FACEBOOK')\n",
    "    \n",
    "#CREAR Object AlcaldeNoticias \n",
    "class AlcaldeNoticias(StructuredNode):\n",
    "    url = StringProperty(unique_index=True)\n",
    "    nombre_Pagina_WEB = StringProperty(unique_index=True)\n",
    "    titulo = StringProperty(unique_index=True)\n",
    "    mensaje = StringProperty(unique_index=True)\n",
    "    fecha = StringProperty(unique_index=True)\n",
    "    browsers = RelationshipFrom('Browsers','BROWSERS ALCALDE')\n",
    "\n",
    "#CREAR Object AlcaldeFacebook \n",
    "class AlcaldeFacebook(StructuredNode):\n",
    "    url = StringProperty(unique_index=True)\n",
    "    nombre_Pagina_WEB = StringProperty(unique_index=True)\n",
    "    titulo = StringProperty(unique_index=True)\n",
    "    mensaje = StringProperty(unique_index=True)\n",
    "    browsers = RelationshipFrom('Browsers','BROWSERS ALCALDE FACEBOOK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar los datos del object Browsers\n",
    "browsersG = Browsers(nombre = \"GOOGLE\").save()\n",
    "browsersE = Browsers(nombre = \"ECOSIA\").save()\n",
    "browsersB = Browsers(nombre = \"BING\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar \n",
    "\n",
    "#URL buscar en noticias del alcalde del Canton Paute RAUL DELGADO \n",
    "noticiasalcalde = 'https://www.google.com/search?q=raul+delgado+alcalde+de+paute&tbm=nws&sxsrf='\n",
    "#Rango de paginas a buscar por Noticias\n",
    "rangoNoticiasAlcalde = 60\n",
    "\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "cont=0\n",
    "contID = 1;\n",
    "contCambioPaginaP=0\n",
    "for i in range(rangoNoticiasAlcalde):\n",
    "    url = noticiasalcalde+str(contCambioPaginaP)\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "    contenido = BeautifulSoup(respuesta.content, \"html.parser\")\n",
    "    contenido = contenido.find_all('div', class_='dbsr')\n",
    "    \n",
    "    contCambioPaginaP=contCambioPaginaP+10\n",
    "    cont=cont\n",
    "    for lista in contenido:\n",
    "        cont=cont+1\n",
    "        \n",
    "        #SACAR URL\n",
    "        url = str(lista.find_all('a'))\n",
    "        url = url.split('href=\"')\n",
    "        url = str(url[1])\n",
    "        url = url.split('\" ping=\"')\n",
    "        url = str(url[0])\n",
    "        \n",
    "        #SACAR NOMBRE DE LA PAGINA WEB\n",
    "        nombreP =str(lista.find_all('div', class_='XTjFC WF4CUc'))\n",
    "        nombrePagina = nombreP.split('</g-img>')\n",
    "        nombrePagina = (nombrePagina[1])\n",
    "        nombrePagina = nombrePagina.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR TITULO\n",
    "        titulo=str(lista.find_all('div', class_='JheGif nDgy9d'))\n",
    "        titulo=titulo.replace('[<div aria-level=\"2\" class=\"JheGif nDgy9d\" role=\"heading\" style=\"-webkit-line-clamp:2\">', '')\n",
    "        titulo=titulo.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR MENSAJE\n",
    "        mensaje = str(lista.find_all('div', class_='Y3v8qd'))\n",
    "        mensaje=mensaje.replace('[<div class=\"Y3v8qd\">', '')\n",
    "        mensaje=mensaje.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR FECHA\n",
    "        fecha=str(lista.find_all('span',class_='WG9SHc'))\n",
    "        fecha=fecha.replace('[<span class=\"WG9SHc\"><span>', '')\n",
    "        fecha=fecha.replace('</span></span>]', '')\n",
    "        #Guardar los datos del object\n",
    "        alcaldeNoticias = AlcaldeNoticias(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje, fecha = fecha).save()\n",
    "        #Guardar los datos del object\n",
    "        browsersG.alcalde.connect(alcaldeNoticias)\n",
    "        contID = contID + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar\n",
    "\n",
    "urlAlcaldeEcosia = 'https://www.ecosia.org/news?q=raul%20delgado&p='\n",
    "rangourlalcaldeEcosia = 20\n",
    "\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "cont=0\n",
    "contCambioPagina=0\n",
    "for i in range(rangourlalcaldeEcosia):\n",
    "    url = urlAlcaldeEcosia+str(contCambioPagina)\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "    contenido = BeautifulSoup(respuesta.content, 'html.parser')\n",
    "    conten = contenido.find_all('section', class_='news__results')\n",
    "    conten = contenido.find_all('div',class_='result__body')\n",
    "    contCambioPagina=contCambioPagina+1\n",
    "    cont=cont\n",
    "    for enlace in conten:\n",
    "        cont=cont+1\n",
    "\n",
    "        url = str(enlace.find_all('h2',class_='result-title'))\n",
    "        url = url.split('data-v-e393cff4=\"\" href=\"')\n",
    "        url = str(url[0])\n",
    "        url = url.split('\" rel=\"noopener\"')\n",
    "        url = str(url[0])\n",
    "\n",
    "        nombrePagina =str(enlace.find_all('div', class_='result__info'))\n",
    "        nombrePagina = nombrePagina.split('cff4=\"\">')\n",
    "        nombrePagina = str(nombrePagina[0])\n",
    "        nombrePagina = nombrePagina.split('</div>')\n",
    "        nombrePagina = str(nombrePagina[0])\n",
    "\n",
    "        titulo = str(enlace.find_all('h2',class_='result-title'))\n",
    "        titulo = titulo.split('target=\"_self\">')\n",
    "        titulo = str(titulo[0])\n",
    "        titulo = titulo.replace('</a> </h2>]','')\n",
    "\n",
    "        mensaje = str(enlace.find_all('', class_='news-result__description'))\n",
    "        mensaje= mensaje.split('data-v-e393cff4=\"\">')\n",
    "        mensaje= str(mensaje[0])\n",
    "        mensaje=mensaje.replace('</p>]', '')\n",
    "\n",
    "        fecha=str(enlace.find_all('time',class_='news-result__date'))\n",
    "        fecha=fecha.split('\">')\n",
    "        fecha=str(fecha[1])\n",
    "        fecha=fecha.replace('</time>]', '')\n",
    "    \n",
    "        alcaldeNoticias = AlcaldeNoticias(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje, fecha = fecha).save()\n",
    "        browsersE.alcalde.connect(alcaldeNoticias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlace: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar \n",
    "\n",
    "urlBingalcalde = 'https://www.bing.com/news/search?q=raul+delgado+alcalde+de+paute'\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    url = urlBingalcalde\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "    contenido = BeautifulSoup(respuesta.content, 'html.parser')\n",
    "    conten = contenido.find_all('div', class_='news-card newsitem cardcommon b_cards2')\n",
    "    print(\"Enlace: \")\n",
    "    for enlace in conten:\n",
    "\n",
    "        url = str(enlace.find_all('a'))\n",
    "        url = url.split('href=\"')\n",
    "        url = str(url[1])\n",
    "        url = url.split('tabindex=\"-1\"')\n",
    "        url = str(url[0])\n",
    "\n",
    "        nombrePagina =str(enlace.find_all('div', class_='source'))\n",
    "        nombrePagina = nombrePagina.split('\">')\n",
    "        nombrePagina = (nombrePagina[2])\n",
    "        nombrePagina = nombrePagina.replace('</a><span><span class=\"news-separator', '')\n",
    "\n",
    "        titulo = str(enlace.find_all('a',class_=\"title\"))\n",
    "        titulo = titulo.split('blank\">')\n",
    "        titulo = str(titulo[1])\n",
    "        titulo = titulo.replace('</a>]','')\n",
    "\n",
    "        mensaje = str(enlace.find_all('div', class_='snippet'))\n",
    "        mensaje= mensaje.split('\"')\n",
    "        mensaje= str(mensaje[3])\n",
    "\n",
    "        fecha=str(enlace.find_all('span'))\n",
    "        fecha=fecha.split('tabindex=\"0\">')\n",
    "        fecha=str(fecha[1])\n",
    "        fecha=fecha.replace('</span>]', '')\n",
    "        \n",
    "        alcaldeNoticias = AlcaldeNoticias(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje, fecha = fecha).save()\n",
    "        browsersB.alcalde.connect(alcaldeNoticias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar \n",
    "\n",
    "#URL buscar en noticias  \n",
    "urlfacebookAlcalde = 'https://www.google.com/search?q=https://www.facebook.com/alcaldiadepaute&start='\n",
    "#Rango de paginas a buscar por Noticias \n",
    "rangourlfacebookAlcalde = 8\n",
    "\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "cont=0\n",
    "contID = 1;\n",
    "contCambioPaginaPartidoA=30\n",
    "for i in range(rangourlfacebookAlcalde):\n",
    "    url = urlfacebookAlcalde+str(contCambioPaginaPartidoA)\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "   \n",
    "    contenido = BeautifulSoup(respuesta.content, \"html.parser\")\n",
    "\n",
    "    contenido = contenido.find_all('div', class_=\"g\")\n",
    "    contCambioPaginaPartidoA=contCambioPaginaPartidoA+10\n",
    "    cont=cont\n",
    "    for lista in contenido:\n",
    "        cont=cont+1\n",
    "        \n",
    "        #SACAR URL\n",
    "        url = str(lista.find_all('a'))\n",
    "        url = url.split('href=\"')\n",
    "        url = str(url[1])\n",
    "        url = url.split('\" ping=\"')\n",
    "        url = str(url[0])\n",
    "        \n",
    "        \n",
    "        #SACAR TITULO DE LA PAGINA WEB \n",
    "        titulo =str(lista.find_all('div', class_='TbwUpd NJjxre'))\n",
    "        titulo = titulo.split('tjvcx\">')\n",
    "        titulo = (titulo[1])\n",
    "        titulo = titulo.split('<span')\n",
    "        titulo = (titulo[0])\n",
    "        \n",
    "        #SACAR NOMBRE DE LA PAGINA WEB \n",
    "        nombrePagina=str(lista.find_all('h3', class_='LC20lb DKV0Md'))\n",
    "        nombrePagina = nombrePagina.split('<span>')\n",
    "        nombrePagina = (nombrePagina[0])\n",
    "        nombrePagina = nombrePagina.split('</span>')\n",
    "        nombrePagina = (nombrePagina[0])\n",
    "        \n",
    "        #SACAR MENSAJE\n",
    "        mensaje = str(lista.find_all('span', class_='aCOpRe'))\n",
    "        mensaje = mensaje.split('<span>')\n",
    "        mensaje = (mensaje[0])\n",
    "        mensaje=mensaje.replace('</span></span>]', '')\n",
    "        mensaje=mensaje.replace('<em>', '')\n",
    "        mensaje=mensaje.replace('</em>', '')\n",
    "        \n",
    "        \n",
    "        alcaldeFacebook = AlcaldeFacebook(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje).save()\n",
    "        browsersG.alcaldeFacebook.connect(alcaldeFacebook)\n",
    "        \n",
    "        contID = contID + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar \n",
    "\n",
    "#URL buscar en noticias del alcalde \n",
    "noticiasalcalde = 'https://www.google.com/search?q=Gustavo+Vera+Arizaga+alcalde+de+gualaceo&tbm=nws&sxsrf='\n",
    "#Rango de paginas a buscar por Noticias\n",
    "rangoNoticiasAlcalde = 60\n",
    "\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "cont=0\n",
    "contID = 1;\n",
    "contCambioPaginaP=0\n",
    "for i in range(rangoNoticiasAlcalde):\n",
    "    url = noticiasalcalde+str(contCambioPaginaP)\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "    contenido = BeautifulSoup(respuesta.content, \"html.parser\")\n",
    "    contenido = contenido.find_all('div', class_='dbsr')\n",
    "    \n",
    "    contCambioPaginaP=contCambioPaginaP+10\n",
    "    cont=cont\n",
    "    for lista in contenido:\n",
    "        cont=cont+1\n",
    "        \n",
    "        #SACAR URL\n",
    "        url = str(lista.find_all('a'))\n",
    "        url = url.split('href=\"')\n",
    "        url = str(url[1])\n",
    "        url = url.split('\" ping=\"')\n",
    "        url = str(url[0])\n",
    "        \n",
    "        #SACAR NOMBRE DE LA PAGINA WEB\n",
    "        nombreP =str(lista.find_all('div', class_='XTjFC WF4CUc'))\n",
    "        nombrePagina = nombreP.split('</g-img>')\n",
    "        nombrePagina = (nombrePagina[1])\n",
    "        nombrePagina = nombrePagina.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR TITULO\n",
    "        titulo=str(lista.find_all('div', class_='JheGif nDgy9d'))\n",
    "        titulo=titulo.replace('[<div aria-level=\"2\" class=\"JheGif nDgy9d\" role=\"heading\" style=\"-webkit-line-clamp:2\">', '')\n",
    "        titulo=titulo.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR MENSAJE\n",
    "        mensaje = str(lista.find_all('div', class_='Y3v8qd'))\n",
    "        mensaje=mensaje.replace('[<div class=\"Y3v8qd\">', '')\n",
    "        mensaje=mensaje.replace('</div>]', '')\n",
    "        \n",
    "        #SACAR FECHA\n",
    "        fecha=str(lista.find_all('span',class_='WG9SHc'))\n",
    "        fecha=fecha.replace('[<span class=\"WG9SHc\"><span>', '')\n",
    "        fecha=fecha.replace('</span></span>]', '')\n",
    "        alcaldeNoticias = AlcaldeNoticias(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje, fecha = fecha).save()\n",
    "        browsersG.alcalde.connect(alcaldeNoticias)\n",
    "        contID = contID + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "#Palabras a Buscar \n",
    "\n",
    " \n",
    "urlfacebookAlcalde = 'https://www.google.com/search?q=https://www.facebook.com/gustavo+vera+alcalde&start='\n",
    "#Rango de paginas a buscar por Noticias \n",
    "rangourlfacebookAlcalde = 8\n",
    "\n",
    "\n",
    "#Encabezasos HTTP Para navegadores\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}\n",
    "\n",
    "cont=0\n",
    "contID = 1;\n",
    "contCambioPaginaPartidoA=30\n",
    "for i in range(rangourlfacebookAlcalde):\n",
    "    url = urlfacebookAlcalde+str(contCambioPaginaPartidoA)\n",
    "    respuesta = requests.get(url, headers = header )\n",
    "   \n",
    "    contenido = BeautifulSoup(respuesta.content, \"html.parser\")\n",
    "\n",
    "    contenido = contenido.find_all('div', class_=\"g\")\n",
    "    contCambioPaginaPartidoA=contCambioPaginaPartidoA+10\n",
    "    cont=cont\n",
    "    for lista in contenido:\n",
    "        cont=cont+1\n",
    "        \n",
    "        #SACAR URL\n",
    "        url = str(lista.find_all('a'))\n",
    "        url = url.split('href=\"')\n",
    "        url = str(url[1])\n",
    "        url = url.split('\" ping=\"')\n",
    "        url = str(url[0])\n",
    "        \n",
    "        \n",
    "        #SACAR TITULO DE LA PAGINA WEB \n",
    "        titulo =str(lista.find_all('div', class_='TbwUpd NJjxre'))\n",
    "        titulo = titulo.split('tjvcx\">')\n",
    "        titulo = (titulo[1])\n",
    "        titulo = titulo.split('<span')\n",
    "        titulo = (titulo[0])\n",
    "        \n",
    "        #SACAR NOMBRE DE LA PAGINA WEB \n",
    "        nombrePagina=str(lista.find_all('h3', class_='LC20lb DKV0Md'))\n",
    "        nombrePagina = nombrePagina.split('<span>')\n",
    "        nombrePagina = (nombrePagina[0])\n",
    "        nombrePagina = nombrePagina.split('</span>')\n",
    "        nombrePagina = (nombrePagina[0])\n",
    "        \n",
    "        #SACAR MENSAJE\n",
    "        mensaje = str(lista.find_all('span', class_='aCOpRe'))\n",
    "        mensaje = mensaje.split('<span>')\n",
    "        mensaje = (mensaje[0])\n",
    "        mensaje=mensaje.replace('</span></span>]', '')\n",
    "        mensaje=mensaje.replace('<em>', '')\n",
    "        mensaje=mensaje.replace('</em>', '')\n",
    "        \n",
    "        alcaldeFacebook = AlcaldeFacebook(url =url,nombre_Pagina_WEB=nombrePagina,titulo = titulo, mensaje = mensaje).save()\n",
    "        browsersG.alcaldeFacebook.connect(alcaldeFacebook)\n",
    "        contID = contID + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
